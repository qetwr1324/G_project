{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1u7eLXQ471-jq6brQij-UrXhj1ovd2qZl",
      "authorship_tag": "ABX9TyMPbX38brfU8htfQ2AU05tu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swha03/G_project/blob/master/cnnmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ3hql4Tx1S5",
        "colab_type": "code",
        "outputId": "bf136b09-cf0b-45bf-9209-20019edc69b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW4ttJzfuMSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e4141c1-208f-4a2d-ef33-15c3ab8fd8d8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiWq-6IQyV0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = '/content/drive/My Drive/Colab Notebooks/sample.dat'\n",
        "modelpath = '/content/drive/My Drive/Colab Notebooks/mymodel.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F93UVc4qjlFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_image(image):\n",
        "    image = image[int(1080 * 0.4):1080, :]\n",
        "    image = cv2.resize(image, (200, 66))\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gL8L-FTv9YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_data(dirname, csvname):\n",
        "    with open(filepath, 'ab') as f:\n",
        "        data = []\n",
        "        csv = pd.read_csv(csvname, sep=',')\n",
        "        joy_values = csv['wheel'].values.tolist()\n",
        "\n",
        "        images = glob.glob(dirname)\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for img in images:\n",
        "\n",
        "            screenshot = cv2.imread(img)\n",
        "\n",
        "            if count < len(joy_values):\n",
        "                screenshot = transform_image(np.array(screenshot))\n",
        "\n",
        "                data.append([screenshot, joy_values[count]])\n",
        "\n",
        "            if count == len(images) - 1:\n",
        "                print('Collected data count - {0}.'.format(count))\n",
        "                pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
        "                data = [] \n",
        "\n",
        "            count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp8aNsH3v_mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(split=False):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        data = []\n",
        "        while True:\n",
        "            try:\n",
        "                temp = pickle.load(f)\n",
        "\n",
        "                if type(temp) is not list:\n",
        "                    temp = np.ndarray.tolist(temp)\n",
        "\n",
        "                data = data + temp\n",
        "            except EOFError:\n",
        "                break\n",
        "        if split:\n",
        "            x_train = []\n",
        "            y_train = []\n",
        "\n",
        "            for i in range(0, len(data)):\n",
        "                x_train.append(data[i][0])\n",
        "                y_train.append(data[i][1])\n",
        "\n",
        "            return np.array(x_train), np.array(y_train)\n",
        "        else:\n",
        "            return np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rCWj_34wEKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    nrows = 66\n",
        "    ncols = 200\n",
        "    img_channels = 3\n",
        "    output_size = 1\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.35, input_shape=(nrows, ncols, img_channels)))\n",
        "    model.add(Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2), padding='valid', activation='elu'))\n",
        "    model.add(Conv2D(filters=36, kernel_size=(5, 5), strides=(2, 2), padding='valid', activation='elu'))\n",
        "    model.add(Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2), padding='valid', activation='elu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='elu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='elu'))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(output_size))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss=keras.losses.mean_squared_error,\n",
        "                  optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKg6aM4rwGSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    if os.path.isfile(modelpath):\n",
        "        model = keras.models.load_model(modelpath)\n",
        "    else:\n",
        "        model = create_model()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBl1lAcKwG8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model):\n",
        "    x, y = read_data(True)\n",
        "\n",
        "    # test data set 0.15 : training data set 85%\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, random_state=1)\n",
        "\n",
        "    model = get_model()\n",
        "\n",
        "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5', monitor='val_loss', verbose=1, mode='auto')\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=8, batch_size=64, verbose=1,\n",
        "              validation_data=(x_valid, y_valid), callbacks=[checkpoint])\n",
        "\n",
        "    model.save(modelpath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfTDZ8pwJc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_data():\n",
        "    data = read_data()\n",
        "    data_size = len(data)\n",
        "    print('Data size  -  ' + str(data_size))\n",
        "\n",
        "    for i in range(data_size - 1, 0, -1):\n",
        "        print(str(image[1]))\n",
        "        cv2.waitKey(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5lnKwhl3clM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0zVtQ5V2nHV",
        "colab_type": "code",
        "outputId": "1b69fc07-e592-42d5-f8e4-1c8a7fcf38ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "collect_data('/content/drive/My Drive/Colab Notebooks/CFile1/*.jpg', '/content/drive/My Drive/Colab Notebooks/CFile1/1.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-23f96760e8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/CFile1/*.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/Colab Notebooks/CFile1/1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-547c113e1769>\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(dirname, csvname)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mscreenshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoy_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghDrz6FgxvpV",
        "colab_type": "code",
        "outputId": "5a4d2199-efa2-4a9f-db78-732dbbbb7be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "model = get_model()\n",
        "train_model(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 697 samples, validate on 123 samples\n",
            "Epoch 1/8\n",
            "697/697 [==============================] - 5s 8ms/step - loss: 0.0195 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: saving model to model-001.h5\n",
            "Epoch 2/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0194 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: saving model to model-002.h5\n",
            "Epoch 3/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0194 - accuracy: 0.0000e+00 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: saving model to model-003.h5\n",
            "Epoch 4/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: saving model to model-004.h5\n",
            "Epoch 5/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: saving model to model-005.h5\n",
            "Epoch 6/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: saving model to model-006.h5\n",
            "Epoch 7/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: saving model to model-007.h5\n",
            "Epoch 8/8\n",
            "697/697 [==============================] - 5s 7ms/step - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0176 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00008: saving model to model-008.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}